{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import glob\n",
    "from tracker import tracker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the Camera\n",
    "# number of inside corners in x & y directions\n",
    "nx = 9\n",
    "ny = 6\n",
    "# prepare object points\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(5,4)\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.05, hspace=0.15)\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    # If found, add to object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "        write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name,img)\n",
    "        img_plt = plt.subplot(grid[idx])\n",
    "        plt.axis('on')\n",
    "        img_plt.set_xticklabels([])\n",
    "        img_plt.set_yticklabels([])\n",
    "        #img_plt.set_aspect('equal')\n",
    "        plt.imshow(img)\n",
    "        plt.title(write_name)\n",
    "        plt.axis('off')\n",
    "plt.show()\n",
    "    #plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take an image, object points, image points, and perform the camera calibration\n",
    "# Undistort the image after camera calibration\n",
    "# load image for reference\n",
    "image = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "img_size = (image.shape[1],image.shape[0])\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump(dist_pickle, open(\"./camera_cal/calibration_pickle.p\", \"wb\"))\n",
    "\n",
    "#Visualizing the before/after distortion on chessboard images\n",
    "undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "img_plt = plt.subplot(grid[0])\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "\n",
    "img_plt = plt.subplot(grid[1])\n",
    "plt.imshow(undist)\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImg = cv2.imread('./test_images/test5.jpg')\n",
    "testImg = cv2.cvtColor(testImg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "undistTest = cv2.undistort(testImg, mtx, dist, None, mtx)\n",
    "\n",
    "#Visualizing the before/after distortion on test images\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)\n",
    "\n",
    "img_plt = plt.subplot(grid[0])\n",
    "plt.imshow(testImg)\n",
    "plt.title('Original test Image')\n",
    "\n",
    "img_plt = plt.subplot(grid[1])\n",
    "plt.imshow(undistTest)\n",
    "plt.title('Undistorted test Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=25, thresh_max=255):\n",
    "    # Convert to grayscale\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(l_channel, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(l_channel, cv2.CV_64F, 0, 1))\n",
    "\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def color_threshold(image, sthresh=(0,255), vthresh=(0,255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel > sthresh[0]) & (s_channel <= sthresh[1])] = 1\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    v_channel = hsv[:,:,2]\n",
    "    v_binary = np.zeros_like(v_channel)\n",
    "    v_binary[(v_channel > vthresh[0]) & (v_channel <= vthresh[1])] = 1\n",
    "\n",
    "    output = np.zeros_like(s_channel)\n",
    "    output[(s_binary == 1) & (v_binary) == 1] = 1\n",
    "\n",
    "    return output\n",
    "\n",
    "def window_mask(width, height, img_ref, center, level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height), max(0,int(center-width)):min(int(center+width),img_ref.shape[1])] = 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.float = float    \n",
    "np.int = int   #module 'numpy' has no attribute 'int'\n",
    "np.object = object    #module 'numpy' has no attribute 'object'\n",
    "np.bool = bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gradx = abs_sobel_thresh(undistTest, orient='x', thresh_min=20, thresh_max=100)\n",
    "\n",
    "#Visualize the results before/after absolute sobel operator is applied on a test image in x direction to find the\n",
    "#vertical lines, since the lane lines are close to being vertical\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(gradx, cmap=\"gray\")\n",
    "plt.title('Absolute sobel threshold in X direction')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Sobel operator in Y-direction to experiment with gradient thresholds\n",
    "grady = abs_sobel_thresh(undistTest, orient='y', thresh_min=20, thresh_max=100)\n",
    "\n",
    "#Visualize the results before/after sobel operator is applied on a test image in y direction \n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(grady, cmap=\"gray\")\n",
    "plt.title('Absolute sobel threshold in Y direction')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment with HLS & HSV color spaces along with thresholds\n",
    "c_binary = color_threshold(undistTest, sthresh=(100,255), vthresh=(50,255))\n",
    "\n",
    "#Visualize the results before/after HLS/HSV  threshold is applied\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(c_binary, cmap=\"gray\")\n",
    "plt.title('After applying color threshold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the binary images using the Sobel thresholds in X/Y directions along with the color threshold to form the final image pipeline\n",
    "preprocessImage = np.zeros_like(undistTest[:,:,0])\n",
    "preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "\n",
    "#Visualize the results before/after combining the images from the pipeline\n",
    "plt.figure(figsize = (18,12))\n",
    "grid = gridspec.GridSpec(1,2)\n",
    "\n",
    "# set the spacing between axes.\n",
    "grid.update(wspace=0.1, hspace=0.1)  \n",
    "\n",
    "plt.subplot(grid[0])\n",
    "plt.imshow(undistTest, cmap=\"gray\")\n",
    "plt.title('Undistorted Image')\n",
    "plt.subplot(grid[1])\n",
    "plt.imshow(preprocessImage, cmap=\"gray\")\n",
    "plt.title('After image processing')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and make a list of test images\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "gidx = 0\n",
    "\n",
    "for idx,fname in enumerate(images):\n",
    "    #read in image\n",
    "    img = cv2.imread(fname)\n",
    "    #undistort the image\n",
    "    img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    #pass image thru the pipeline\n",
    "    preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=12, thresh_max=255)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=25, thresh_max=255)\n",
    "    c_binary = color_threshold(img, sthresh=(100,255), vthresh=(50,255))\n",
    "    preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "\n",
    "    bot_width = .76 # percentage of bottom trapezoidal height\n",
    "    mid_width = .08 # percentage of mid trapezoidal height\n",
    "    height_pct = .62 # percentage of trapezoidal height\n",
    "    bottom_trim= .935 # percentage from top to bottom avoiding the hood of the car\n",
    "\n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct],[img.shape[1]*(0.5+mid_width/2),img.shape[0]*height_pct],[img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim],[img.shape[1]*(0.5-bot_width/2), img.shape[0]*bottom_trim]])\n",
    "    offset = img_size[0]*0.25\n",
    "    dst = np.float32([[offset,0],[img_size[0]-offset,0],[img_size[0]-offset,img_size[1]],[offset,img_size[1]]])\n",
    "    \n",
    "    #perform the warp perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessImage,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #Visualize the results before/after warping for a birds-eye view along with the source & destination co-ordinate locations\n",
    "    plt.figure(figsize = (30,20))\n",
    "    grid = gridspec.GridSpec(8,2)\n",
    "    # set the spacing between axes.\n",
    "    grid.update(wspace=0.05, hspace=0.05)  \n",
    "\n",
    "    plt.subplot(grid[gidx])\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    for i in range(4):\n",
    "        plt.plot(src[i][0],src[i][1],'rs')\n",
    "    plt.title('Undistorted Image')\n",
    "\n",
    "    plt.subplot(grid[gidx+1])\n",
    "    plt.imshow(warped, cmap=\"gray\")\n",
    "    for i in range(4):\n",
    "        plt.plot(dst[i][0],dst[i][1],'rs')\n",
    "    plt.title('Birds eye view')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gidx=0\n",
    "\n",
    "for idx,fname in enumerate(images):\n",
    "    #read in image\n",
    "    img = cv2.imread(fname)\n",
    "    #undistort the image\n",
    "    img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=12, thresh_max=255)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=25, thresh_max=255)\n",
    "    c_binary = color_threshold(img, sthresh=(100,255), vthresh=(50,255))\n",
    "    preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    bot_width = .76 # percentage of bottom trapezoidal height\n",
    "    mid_width = .08 # percentage of mid trapezoidal height\n",
    "    height_pct = .62 # percentage of trapezoidal height\n",
    "    bottom_trim= .935 # percentage from top to bottom avoiding the hood of the car\n",
    "    \n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct],[img.shape[1]*(0.5+mid_width/2),img.shape[0]*height_pct],[img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim],[img.shape[1]*(0.5-bot_width/2), img.shape[0]*bottom_trim]])\n",
    "    offset = img_size[0]*0.25\n",
    "    dst = np.float32([[offset,0],[img_size[0]-offset,0],[img_size[0]-offset,img_size[1]],[offset,img_size[1]]])   \n",
    "    \n",
    "    #perform the warp perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessImage, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    window_width = 25\n",
    "    window_height = 80\n",
    "    \n",
    "    #set up the overall class to do the lane line tracking\n",
    "    curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "    \n",
    "    window_centroids = curve_centers.find_window_centroids(warped)\n",
    "    \n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "        \n",
    "    # points used to find the right & left lanes\n",
    "    rightx = []\n",
    "    leftx = []\n",
    "\n",
    "    # Go through each level and draw the windows \n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        # Add center value found in frame to the list of lane points per left, right\n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "    result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "    \n",
    "    #fit the lane boundaries to the left, right center positions found\n",
    "    yvals = range(0,warped.shape[0])\n",
    "    \n",
    "    res_yvals = np.arange(warped.shape[0]-(window_height/2),0,-window_height)\n",
    "    \n",
    "    left_fit = np.polyfit(res_yvals, leftx, 2)\n",
    "    left_fitx = left_fit[0]*yvals*yvals + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx = np.array(left_fitx,np.int32)\n",
    "    \n",
    "    right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals*yvals + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx = np.array(right_fitx,np.int32)\n",
    "    \n",
    "    left_lane = np.array(list(zip(np.concatenate((left_fitx-window_width/2, left_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    right_lane = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    middle_marker = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "\n",
    "    road = np.zeros_like(img)\n",
    "    road_bkg = np.zeros_like(img)\n",
    "    cv2.fillPoly(road,[left_lane],color=[255,0,0])\n",
    "    cv2.fillPoly(road,[right_lane],color=[0,0,255])\n",
    "    cv2.fillPoly(road_bkg,[left_lane],color=[255,255,255])\n",
    "    cv2.fillPoly(road_bkg,[right_lane],color=[255,255,255])\n",
    "\n",
    "    road_warped = cv2.warpPerspective(road,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    road_warped_bkg= cv2.warpPerspective(road_bkg,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    base = cv2.addWeighted(img,1.0,road_warped, -1.0, 0.0)\n",
    "    result = cv2.addWeighted(base,1.0,road_warped, 1.0, 0.0)\n",
    "    ym_per_pix = curve_centers.ym_per_pix # meters per pixel in y dimension\n",
    "    xm_per_pix = curve_centers.xm_per_pix # meters per pixel in x dimension\n",
    "\n",
    "    curve_fit_cr = np.polyfit(np.array(res_yvals,np.float32)*ym_per_pix,np.array(leftx,np.float32)*xm_per_pix,2)\n",
    "    curverad = ((1 + (2*curve_fit_cr[0]*yvals[-1]*ym_per_pix + curve_fit_cr[1])**2)**1.5) /np.absolute(2*curve_fit_cr[0])\n",
    "    \n",
    "    # Calculate the offset of the car on the road\n",
    "    camera_center = (left_fitx[-1] + right_fitx[-1])/2\n",
    "    center_diff = (camera_center-warped.shape[1]/2)*xm_per_pix\n",
    "    side_pos = 'left'\n",
    "    if center_diff <= 0:\n",
    "        side_pos = 'right'\n",
    "\n",
    "    # draw the text showing curvature, offset & speed\n",
    "    cv2.putText(result, 'Radius of Curvature='+str(round(curverad,3))+'m ',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "    cv2.putText(result, 'Vehicle is '+str(abs(round(center_diff,3)))+'m '+side_pos+' of center',(50,100), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "\n",
    "    plt.imshow(result, cmap='gray')\n",
    "    plt.title('Final image results')\n",
    "    plt.show()\n",
    "    \n",
    "    write_name='./test_images/tracked'+str(idx)+'.jpg'\n",
    "    cv2.imwrite(write_name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the process videos function\n",
    "def process_image(img):\n",
    "    #undistort the image\n",
    "    img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    warptrap = np.copy(img)\n",
    "    \n",
    "    preprocessImage = np.zeros_like(img[:,:,0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=12, thresh_max=255)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=25, thresh_max=255)\n",
    "    c_binary = color_threshold(img, sthresh=(100,255), vthresh=(50,255))\n",
    "    preprocessImage[((gradx == 1) & (grady ==1) | (c_binary == 1))] = 255\n",
    "\n",
    "    binaryImage = np.copy(preprocessImage)\n",
    "    binaryImage = np.array(cv2.merge((binaryImage,binaryImage,binaryImage)),np.uint8)\n",
    "    cv2.putText(binaryImage, 'Binary Image',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    bot_width = .76 # percentage of bottom trapezoidal height\n",
    "    mid_width = .08 # percentage of mid trapezoidal height\n",
    "    height_pct = .62 # percentage of trapezoidal height\n",
    "    bottom_trim= .935 # percentage from top to bottom avoiding the hood of the car\n",
    "    \n",
    "    src = np.float32([[img.shape[1]*(0.5-mid_width/2), img.shape[0]*height_pct],[img.shape[1]*(0.5+mid_width/2),img.shape[0]*height_pct],[img.shape[1]*(0.5+bot_width/2), img.shape[0]*bottom_trim],[img.shape[1]*(0.5-bot_width/2), img.shape[0]*bottom_trim]])\n",
    "    offset = img_size[0]*0.25\n",
    "    dst = np.float32([[offset,0],[img_size[0]-offset,0],[img_size[0]-offset,img_size[1]],[offset,img_size[1]]])   \n",
    "    \n",
    "    cv2.line(warptrap, (int(src[0][0]), int(src[0][1])), (int(src[1][0]), int(src[1][1])), [255,0,0], 10, cv2.LINE_AA)\n",
    "    cv2.line(warptrap, (int(src[1][0]), int(src[1][1])), (int(src[2][0]), int(src[2][1])), [255,0,0], 10, cv2.LINE_AA)\n",
    "    cv2.line(warptrap, (int(src[2][0]), int(src[2][1])), (int(src[3][0]), int(src[3][1])), [255,0,0], 10, cv2.LINE_AA)\n",
    "    cv2.line(warptrap, (int(src[3][0]), int(src[3][1])), (int(src[0][0]), int(src[0][1])), [255,0,0], 10, cv2.LINE_AA)\n",
    "    \n",
    "    #perform the warp perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(preprocessImage, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    window_width = 25\n",
    "    window_height = 80\n",
    "    \n",
    "    #set up the overall class to do the lane line tracking\n",
    "    curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "    \n",
    "    window_centroids = curve_centers.find_window_centroids(warped)\n",
    "    \n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "        \n",
    "    # points used to find the right & left lanes\n",
    "    rightx = []\n",
    "    leftx = []\n",
    "\n",
    "    # Go through each level and draw the windows \n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        # Add center value found in frame to the list of lane points per left, right\n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "    result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "\n",
    "    windowfit = np.copy(result)\n",
    "    cv2.putText(windowfit, 'Sliding window results',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "    warpage1 = np.copy(warpage)\n",
    "    cv2.putText(warpage1, 'Bird\\'s-eye View',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.line(warpage1, (int(dst[0][0]), int(dst[0][1])), (int(dst[1][0]), int(dst[1][1])), [0,0,255], 10, cv2.LINE_AA)\n",
    "    cv2.line(warpage1, (int(dst[1][0]), int(dst[1][1])), (int(dst[2][0]), int(dst[2][1])), [0,0,255], 10, cv2.LINE_AA)\n",
    "    cv2.line(warpage1, (int(dst[2][0]), int(dst[2][1])), (int(dst[3][0]), int(dst[3][1])), [0,0,255], 10, cv2.LINE_AA)\n",
    "    cv2.line(warpage1, (int(dst[3][0]), int(dst[3][1])), (int(dst[0][0]), int(dst[0][1])), [0,0,255], 10, cv2.LINE_AA)\n",
    "    \n",
    "    #fit the lane boundaries to the left, right center positions found\n",
    "    yvals = range(0,warped.shape[0])\n",
    "    \n",
    "    res_yvals = np.arange(warped.shape[0]-(window_height/2),0,-window_height)\n",
    "    \n",
    "    left_fit = np.polyfit(res_yvals, leftx, 2)\n",
    "    left_fitx = left_fit[0]*yvals*yvals + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx = np.array(left_fitx,np.int32)\n",
    "    \n",
    "    right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals*yvals + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx = np.array(right_fitx,np.int32)\n",
    "    \n",
    "    left_lane = np.array(list(zip(np.concatenate((left_fitx-window_width/2, left_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    right_lane = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    middle_marker = np.array(list(zip(np.concatenate((right_fitx-window_width/2, right_fitx[::-1]+window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    inner_lane = np.array(list(zip(np.concatenate((left_fitx+window_width/2, right_fitx[::-1]-window_width/2),axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "\n",
    "    road = np.zeros_like(img)\n",
    "    road_bkg = np.zeros_like(img)\n",
    "    cv2.fillPoly(road,[left_lane],color=[255,0,0])\n",
    "    cv2.fillPoly(road,[right_lane],color=[0,0,255])\n",
    "    cv2.fillPoly(road,[inner_lane],color=[0,255,0])\n",
    "    cv2.fillPoly(road_bkg,[left_lane],color=[255,255,255])\n",
    "    cv2.fillPoly(road_bkg,[right_lane],color=[255,255,255])\n",
    "    \n",
    "    #Results screen portion for polynomial fit\n",
    "    road1 = np.copy(road)\n",
    "    cv2.putText(road1, 'Polynomial fit',(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "    road_warped = cv2.warpPerspective(road,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    road_warped_bkg= cv2.warpPerspective(road_bkg,Minv,img_size,flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    base = cv2.addWeighted(img,1.0,road_warped, -1.0, 0.0)\n",
    "    result = cv2.addWeighted(base,1.0,road_warped, 1.0, 0.0)\n",
    "    ym_per_pix = curve_centers.ym_per_pix # meters per pixel in y dimension\n",
    "    xm_per_pix = curve_centers.xm_per_pix # meters per pixel in x dimension\n",
    "\n",
    "    curve_fit_cr = np.polyfit(np.array(res_yvals,np.float32)*ym_per_pix,np.array(leftx,np.float32)*xm_per_pix,2)\n",
    "    curverad = ((1 + (2*curve_fit_cr[0]*yvals[-1]*ym_per_pix + curve_fit_cr[1])**2)**1.5) /np.absolute(2*curve_fit_cr[0])\n",
    "    \n",
    "    # Calculate the offset of the car on the road\n",
    "    camera_center = (left_fitx[-1] + right_fitx[-1])/2\n",
    "    center_diff = (camera_center-warped.shape[1]/2)*xm_per_pix\n",
    "    side_pos = 'left'\n",
    "    if center_diff <= 0:\n",
    "        side_pos = 'right'\n",
    "\n",
    "    # draw the text showing curvature, offset & speed\n",
    "    cv2.putText(result, 'Radius of Curvature='+str(round(curverad,3))+'m ',(25,25),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "    cv2.putText(result, 'Vehicle is '+str(abs(round(center_diff,3)))+'m '+side_pos+' of center',(25,50), cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "\n",
    "    height, width = 1080, 1920\n",
    "    FinalScreen = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    FinalScreen[0:1080,0:1920] = cv2.resize(result, (1920,1080), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[0:360,1280:1920] = cv2.resize(warptrap, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    FinalScreen[360:720,1280:1920] = cv2.resize(warpage1, (640,360), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return FinalScreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('input1.mp4')\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap = cv2.VideoCapture(\"https://192.168.1.7:8080/video\")\n",
    "\n",
    "frame_counter = 0\n",
    "while(True):\n",
    "    flag, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (600,400))\n",
    "    \n",
    "    frame_counter += 1\n",
    "    if frame_counter == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        frame_counter = 0\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    cv2.imshow('Input', frame)\n",
    "    out_frame = process_image(frame)\n",
    "    out_frame = cv2.resize(out_frame, (600,400))\n",
    "    cv2.imshow('Output', out_frame)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
